{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc50f680",
   "metadata": {},
   "source": [
    "### Loading the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d6e3e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827988fc",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d62d29ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AER_credit_card_data.csv', <http.client.HTTPMessage at 0x1fef48ced00>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/57748687/downloading-files-in-jupyter-wget-on-windows\n",
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv'\n",
    "filename = 'AER_credit_card_data.csv'\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4b5df649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  card  reports       age  income     share  expenditure owner selfemp  \\\n",
       "0  yes        0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1  yes        0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2  yes        0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3  yes        0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4  yes        0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "\n",
       "   dependents  months  majorcards  active  \n",
       "0           3      54           1      12  \n",
       "1           3      34           1      13  \n",
       "2           4      58           1       5  \n",
       "3           0      25           1       7  \n",
       "4           2      64           1       5  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('AER_credit_card_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8cdaef7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card            object\n",
       "reports          int64\n",
       "age            float64\n",
       "income         float64\n",
       "share          float64\n",
       "expenditure    float64\n",
       "owner           object\n",
       "selfemp         object\n",
       "dependents       int64\n",
       "months           int64\n",
       "majorcards       int64\n",
       "active           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0b146",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "70efee24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  card  reports       age  income     share  expenditure owner selfemp  \\\n",
       "0  yes        0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1  yes        0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2  yes        0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3  yes        0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4  yes        0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "\n",
       "   dependents  months  majorcards  active  target  \n",
       "0           3      54           1      12       1  \n",
       "1           3      34           1      13       1  \n",
       "2           4      58           1       5       1  \n",
       "3           0      25           1       7       1  \n",
       "4           2      64           1       5       1  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = (df['card'] == 'yes').astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b75c1c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes    1023\n",
      "no      296\n",
      "Name: card, dtype: int64\n",
      "1    1023\n",
      "0     296\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking if the target column has been properly mapped\n",
    "print(df.card.value_counts())\n",
    "print(df.target.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538eea0",
   "metadata": {},
   "source": [
    "### Splitting the data into train, val and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eafaf111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((791, 13), (264, 13), (264, 13))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "12c309a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['target'].values\n",
    "y_val = df_val['target'].values\n",
    "y_test = df_test['target'].values\n",
    "\n",
    "del df_train['target']\n",
    "del df_val['target']\n",
    "del df_test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df122c11",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that\n",
    "\n",
    "For each numerical variable, use it as score and compute AUC with the card variable.\n",
    "Use the training dataset for that.\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. -df_train['expenditure'])\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "* reports\n",
    "* dependents\n",
    "* active\n",
    "* share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0c676736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reports : 0.7166629860689376\n",
      "dependents : 0.5327757227773791\n",
      "active : 0.6043173411362006\n",
      "share : 0.989183643423692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc, roc_auc_score\n",
    "print(f\"reports : {roc_auc_score(df_train['card'], -df_train['reports'])}\")\n",
    "print(f\"dependents : {roc_auc_score(df_train['card'], -df_train['dependents'])}\")\n",
    "print(f\"active : {roc_auc_score(df_train['card'], df_train['active'])}\")\n",
    "print(f\"share : {roc_auc_score(df_train['card'], df_train['share'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af39899",
   "metadata": {},
   "source": [
    "### Answer 1 - share has the higest auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9356109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_columns = [\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19af9581",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "From now on, use these columns only:\n",
    "\n",
    "[\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]\n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
    "\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eb4937f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "\n",
    "train_dict = df_train[use_columns].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97569084",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "* 0.615\n",
    "* 0.515\n",
    "* 0.715\n",
    "* 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bf4801e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dict = df_val[use_columns].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "y_preds = model.predict(X_val)\n",
    "#model.score(X_val, y_val)\n",
    "\n",
    "round(roc_auc_score(y_val, y_pred),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be54c46",
   "metadata": {},
   "source": [
    "### Answer 2 : 0.995"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961cf77e",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "* Evaluate the model on the validation dataset on all thresholds from 0.0 to 1.0 with step 0.01.\n",
    "* For each threshold, compute precision and recall.\n",
    "* Plot them.\n",
    "* At which threshold precision and recall curves intersect? -\n",
    "\n",
    "    * 0.1\n",
    "    * 0.3\n",
    "    * 0.6\n",
    "    * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8af4866b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0: precision : 0.799, recall : 1.0\n",
      "0.02: precision : 0.872, recall : 1.0\n",
      "0.04: precision : 0.906, recall : 1.0\n",
      "0.06: precision : 0.917, recall : 1.0\n",
      "0.08: precision : 0.921, recall : 0.995\n",
      "0.1: precision : 0.925, recall : 0.995\n",
      "0.12: precision : 0.929, recall : 0.995\n",
      "0.14: precision : 0.959, recall : 0.986\n",
      "0.16: precision : 0.967, recall : 0.986\n",
      "0.18: precision : 0.976, recall : 0.981\n",
      "0.2: precision : 0.976, recall : 0.981\n",
      "0.22: precision : 0.976, recall : 0.981\n",
      "0.24: precision : 0.976, recall : 0.976\n",
      "0.27: precision : 0.976, recall : 0.976\n",
      "0.29: precision : 0.976, recall : 0.976\n",
      "0.31: precision : 0.981, recall : 0.972\n",
      "0.33: precision : 0.981, recall : 0.972\n",
      "0.35: precision : 0.995, recall : 0.972\n",
      "0.37: precision : 0.995, recall : 0.972\n",
      "0.39: precision : 0.995, recall : 0.972\n",
      "0.41: precision : 0.995, recall : 0.972\n",
      "0.43: precision : 0.995, recall : 0.967\n",
      "0.45: precision : 0.995, recall : 0.967\n",
      "0.47: precision : 0.995, recall : 0.967\n",
      "0.49: precision : 0.995, recall : 0.967\n",
      "0.51: precision : 0.995, recall : 0.967\n",
      "0.53: precision : 0.995, recall : 0.967\n",
      "0.55: precision : 0.995, recall : 0.967\n",
      "0.57: precision : 0.995, recall : 0.967\n",
      "0.59: precision : 0.995, recall : 0.967\n",
      "0.61: precision : 0.995, recall : 0.967\n",
      "0.63: precision : 0.995, recall : 0.967\n",
      "0.65: precision : 0.995, recall : 0.967\n",
      "0.67: precision : 0.995, recall : 0.967\n",
      "0.69: precision : 0.995, recall : 0.967\n",
      "0.71: precision : 0.995, recall : 0.967\n",
      "0.73: precision : 0.995, recall : 0.967\n",
      "0.76: precision : 0.995, recall : 0.967\n",
      "0.78: precision : 0.995, recall : 0.967\n",
      "0.8: precision : 0.995, recall : 0.967\n",
      "0.82: precision : 0.995, recall : 0.967\n",
      "0.84: precision : 0.995, recall : 0.967\n",
      "0.86: precision : 1.0, recall : 0.967\n",
      "0.88: precision : 1.0, recall : 0.967\n",
      "0.9: precision : 1.0, recall : 0.967\n",
      "0.92: precision : 1.0, recall : 0.967\n",
      "0.94: precision : 1.0, recall : 0.967\n",
      "0.96: precision : 1.0, recall : 0.967\n",
      "0.98: precision : 1.0, recall : 0.962\n",
      "1.0: precision : 1.0, recall : 0.848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "#from sklearn.metrics import precision_recall_curve\n",
    "precision_scores=[]\n",
    "recall_scores = []\n",
    "thresholds = np.linspace(0, 1)\n",
    "for i in thresholds:\n",
    "    precision = precision_score(y_val, y_pred >= i)\n",
    "    recall = recall_score(y_val, y_pred >= i)\n",
    "    print(f\"{i.round(2)}: precision : {precision.round(3)}, recall : {recall.round(3)}\")\n",
    "    #print(f\"{i.round(2)}: recall:{recall.round(3)}\")\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2b1474df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1fef49a5dc0>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds, precision_scores)\n",
    "plt.plot(thresholds, recall_scores)\n",
    "plt.legend(labels=['precision', 'recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc3052",
   "metadata": {},
   "source": [
    "### Answer 3 :The precision and recall curves seem to intersect somewhere near 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf65eb5",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "* Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "* This is the formula for computing :\n",
    "     * f1 = 2 * ((P*R)/(P+R))\n",
    " \n",
    "\n",
    "* <b>Where P = precision and R = recall.</b>\n",
    "\n",
    "* Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01 using the validation set\n",
    "\n",
    "* At which threshold F1 is maximal?\n",
    "\n",
    "    * 0.1\n",
    "    * 0.4\n",
    "    * 0.6\n",
    "    * 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e555c815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 : f1_score : 0.8884210526315789\n",
      "0.02 : f1_score : 0.9315673289183224\n",
      "0.04 : f1_score : 0.9504504504504505\n",
      "0.06 : f1_score : 0.9569160997732427\n",
      "0.08 : f1_score : 0.9567198177676538\n",
      "0.1 : f1_score : 0.958904109589041\n",
      "0.12 : f1_score : 0.9610983981693364\n",
      "0.14 : f1_score : 0.9719626168224299\n",
      "0.16 : f1_score : 0.9765258215962441\n",
      "0.18 : f1_score : 0.9787234042553191\n",
      "0.2 : f1_score : 0.9787234042553191\n",
      "0.22 : f1_score : 0.9787234042553191\n",
      "0.24 : f1_score : 0.976303317535545\n",
      "0.27 : f1_score : 0.976303317535545\n",
      "0.29 : f1_score : 0.976303317535545\n",
      "0.31 : f1_score : 0.9761904761904763\n",
      "0.33 : f1_score : 0.9761904761904763\n",
      "0.35 : f1_score : 0.9832134292565947\n",
      "0.37 : f1_score : 0.9832134292565947\n",
      "0.39 : f1_score : 0.9832134292565947\n",
      "0.41 : f1_score : 0.9832134292565947\n",
      "0.43 : f1_score : 0.9807692307692307\n",
      "0.45 : f1_score : 0.9807692307692307\n",
      "0.47 : f1_score : 0.9807692307692307\n",
      "0.49 : f1_score : 0.9807692307692307\n",
      "0.51 : f1_score : 0.9807692307692307\n",
      "0.53 : f1_score : 0.9807692307692307\n",
      "0.55 : f1_score : 0.9807692307692307\n",
      "0.57 : f1_score : 0.9807692307692307\n",
      "0.59 : f1_score : 0.9807692307692307\n",
      "0.61 : f1_score : 0.9807692307692307\n",
      "0.63 : f1_score : 0.9807692307692307\n",
      "0.65 : f1_score : 0.9807692307692307\n",
      "0.67 : f1_score : 0.9807692307692307\n",
      "0.69 : f1_score : 0.9807692307692307\n",
      "0.71 : f1_score : 0.9807692307692307\n",
      "0.73 : f1_score : 0.9807692307692307\n",
      "0.76 : f1_score : 0.9807692307692307\n",
      "0.78 : f1_score : 0.9807692307692307\n",
      "0.8 : f1_score : 0.9807692307692307\n",
      "0.82 : f1_score : 0.9807692307692307\n",
      "0.84 : f1_score : 0.9807692307692307\n",
      "0.86 : f1_score : 0.983132530120482\n",
      "0.88 : f1_score : 0.983132530120482\n",
      "0.9 : f1_score : 0.983132530120482\n",
      "0.92 : f1_score : 0.983132530120482\n",
      "0.94 : f1_score : 0.983132530120482\n",
      "0.96 : f1_score : 0.983132530120482\n",
      "0.98 : f1_score : 0.9806763285024155\n",
      "1.0 : f1_score : 0.9179487179487179\n"
     ]
    }
   ],
   "source": [
    "f1 = []\n",
    "thresholds = np.linspace(0, 1)\n",
    "for i in thresholds:\n",
    "    precision = precision_score(y_val, y_pred >= i)\n",
    "    recall = recall_score(y_val, y_pred >= i)\n",
    "    f1_sc = 2 * ((precision * recall) / (precision + recall))\n",
    "    print(f\"{i.round(2)} : f1_score : {f1_sc}\")\n",
    "    f1.append(f1_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bac953bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 : f1_score : 0.958904109589041\n",
      "0.4 : f1_score : 0.9832134292565947\n",
      "0.6 : f1_score : 0.9807692307692307\n",
      "0.7 : f1_score : 0.9807692307692307\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.1, 0.4, 0.6, 0.7]\n",
    "for i in thresholds:\n",
    "    precision = precision_score(y_val, y_pred >= i)\n",
    "    recall = recall_score(y_val, y_pred >= i)\n",
    "    f1_sc = 2 * ((precision * recall) / (precision + recall))\n",
    "    print(f\"{i} : f1_score : {f1_sc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc8955d",
   "metadata": {},
   "source": [
    "### Answer 4 - The f1 score is maximum around 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b270c",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "* Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "* KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "* Iterate over different folds of df_full_train\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "* Use AUC to evaluate the model on validation\n",
    "* How large is standard devidation of the AUC scores across different folds?\n",
    "\n",
    "    * 0.003\n",
    "    * 0.014\n",
    "    * 0.09\n",
    "    * 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "37eff33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996 0.003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "    \n",
    "    y_train = df_train['target'].values\n",
    "    y_val = df_val['target'].values\n",
    "    \n",
    "    del df_train['target']\n",
    "    del df_val['target']\n",
    "    \n",
    "    dv_k = DictVectorizer(sparse=False)\n",
    "    train_dict = df_train[use_columns].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "    \n",
    "    val_dict = df_val[use_columns].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "    \n",
    "    model_k = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model_k.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model_k.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    \n",
    "    scores.append(auc)\n",
    "\n",
    "print(np.mean(scores).round(3), np.std(scores).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0dde014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d57327",
   "metadata": {},
   "source": [
    "### Answer 5 : The standard deviation is 0.03 across different folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54873159",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "* Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "* Iterate over the following C values: [0.01, 0.1, 1, 10]\n",
    "* Initialize KFold with the same parameters as previously\n",
    "* Use these parametes for the model: <b>LogisticRegression(solver='liblinear', C=C, max_iter=1000)</b>\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "* Which C leads to the best mean score?\n",
    "\n",
    "    * 0.01\n",
    "    * 0.1\n",
    "    * 1\n",
    "    * 10\n",
    "\n",
    "* If you have ties, select the score with the lowest std. If you still have ties, select the smallest C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1aca81df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec46c68ade704efe80bb8d845c44a743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 0.996 +- 0.003\n",
      "C=0.1 0.996 +- 0.003\n",
      "C=1 0.996 +- 0.003\n",
      "C=10 0.996 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "for C in tqdm([0.01, 0.1, 1, 10]):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train['target'].values\n",
    "        y_val = df_val['target'].values\n",
    "    \n",
    "        del df_train['target']\n",
    "        del df_val['target']\n",
    "    \n",
    "        dv_k = DictVectorizer(sparse=False)\n",
    "        train_dict = df_train[use_columns].to_dict(orient='records')\n",
    "        X_train = dv.fit_transform(train_dict)\n",
    "    \n",
    "        val_dict = df_val[use_columns].to_dict(orient='records')\n",
    "        X_val = dv.transform(val_dict)\n",
    "    \n",
    "        model_k = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "        model_k.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = model_k.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "    \n",
    "        scores.append(auc)\n",
    "\n",
    "\n",
    "    print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32c93d4",
   "metadata": {},
   "source": [
    "### Answer 6 - We have ties for both standard deviation and mean. Hence we choose the score with lowest C value i.e. 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927ee08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
